{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "W0_KJao-7mS9",
      "metadata": {
        "id": "W0_KJao-7mS9"
      },
      "source": [
        "#### Install unsloth on Colab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "n4Ce7CWwfbDd",
      "metadata": {
        "id": "n4Ce7CWwfbDd"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "import os, re\n",
        "if \"COLAB_\" not in \"\".join(os.environ.keys()):\n",
        "    !pip install unsloth\n",
        "else:\n",
        "    # Do this only in Colab notebooks! Otherwise use pip install unsloth\n",
        "    import torch; v = re.match(r\"[0-9\\.]{3,}\", str(torch.__version__)).group(0)\n",
        "    xformers = \"xformers==\" + (\"0.0.32.post2\" if v == \"2.8.0\" else \"0.0.29.post3\")\n",
        "    !pip install --no-deps bitsandbytes accelerate {xformers} peft trl triton cut_cross_entropy unsloth_zoo\n",
        "    !pip install sentencepiece protobuf \"datasets>=3.4.1,<4.0.0\" \"huggingface_hub>=0.34.0\" hf_transfer\n",
        "    !pip install --no-deps unsloth\n",
        "\n",
        "!pip install transformers==4.55.4\n",
        "!pip install --no-deps trl==0.22.2\n",
        "# !pip install transformers\n",
        "# !pip install --no-deps trl"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "MDWGEnZy7mPo",
      "metadata": {
        "id": "MDWGEnZy7mPo"
      },
      "source": [
        "#### Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3pemlhygff1W",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3pemlhygff1W",
        "outputId": "df989739-9f1c-4ed2-c9e1-fd03a8a200c2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ðŸ¦¥ Unsloth: Will patch your computer to enable 2x faster free finetuning.\n"
          ]
        }
      ],
      "source": [
        "from unsloth import FastVisionModel\n",
        "from unsloth.trainer import UnslothVisionDataCollator\n",
        "from trl import SFTTrainer, SFTConfig\n",
        "# TRL (Transformer Reinforcement Learning)\n",
        "from unsloth import unsloth_train\n",
        "\n",
        "from datetime import datetime\n",
        "from datasets import load_dataset\n",
        "from huggingface_hub import whoami, HfApi, create_repo\n",
        "from pathlib import Path\n",
        "\n",
        "import os, json, gc, torch\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from collections import defaultdict\n",
        "from transformers import TrainerCallback"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7f451446",
      "metadata": {
        "id": "7f451446"
      },
      "source": [
        "#### Configuration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6791fad7",
      "metadata": {
        "id": "6791fad7"
      },
      "outputs": [],
      "source": [
        "args = {\n",
        "    \"lr\": 2e-4,\n",
        "    \"lora_r\": 16,\n",
        "    \"lora_a\": 16,\n",
        "    \"max_length\": 2048,\n",
        "    \"batch_size\": 8,\n",
        "    \"gradient_accum\": 2,\n",
        "    \"warmup\": 50,\n",
        "    \"num_train_epochs\": 10,\n",
        "    \"eval_steps\": 100,\n",
        "    \"save_steps\": 100,\n",
        "    \"temperature\": 1.5,\n",
        "    \"logging_steps\": 5,\n",
        "    \"early_stopping_patience\": 3,\n",
        "    \"overfitting_threshold\": 0.15,\n",
        "    \"save_total_limit\": 2,\n",
        "    \"use_validation\": True,\n",
        "    \"hf_username\": \"Laya-hmkh\",\n",
        "    \"dataset_name\": \"maomao1234/r1_report_generation\",\n",
        "    \"token\": \"\" #Replace your own token here\n",
        "}\n",
        "\n",
        "print(\"âœ“ Hyperparameters loaded\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "pr15wo9LYVay",
      "metadata": {
        "id": "pr15wo9LYVay"
      },
      "source": [
        "#### Train Monitoring"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8E8qwTUTpy_D",
      "metadata": {
        "id": "8E8qwTUTpy_D"
      },
      "outputs": [],
      "source": [
        "class TrainingMonitor:\n",
        "    \"\"\"Comprehensive training monitoring and visualization\"\"\"\n",
        "\n",
        "    def __init__(self, output_dir=\"monitoring\", use_validation=True):\n",
        "        self.output_dir = Path(output_dir)\n",
        "        self.output_dir.mkdir(exist_ok=True, parents=True)\n",
        "        self.use_validation = use_validation\n",
        "\n",
        "        # Metrics storage\n",
        "        self.metrics = defaultdict(list)\n",
        "        self.train_losses = []\n",
        "        self.val_losses = []\n",
        "        self.learning_rates = []\n",
        "        self.gpu_memory = []\n",
        "        self.steps = []\n",
        "        self.val_steps = []\n",
        "\n",
        "        # Best model tracking\n",
        "        self.best_val_loss = float('inf')\n",
        "        self.best_step = 0\n",
        "        self.patience_counter = 0\n",
        "\n",
        "    def log_metrics(self, step, metrics_dict):\n",
        "        \"\"\"Log metrics at each step\"\"\"\n",
        "        self.steps.append(step)\n",
        "\n",
        "        for key, value in metrics_dict.items():\n",
        "            self.metrics[key].append(value)\n",
        "\n",
        "        if 'train_loss' in metrics_dict:\n",
        "            self.train_losses.append(metrics_dict['train_loss'])\n",
        "\n",
        "        if 'learning_rate' in metrics_dict:\n",
        "            self.learning_rates.append(metrics_dict['learning_rate'])\n",
        "\n",
        "        if 'gpu_memory_gb' in metrics_dict:\n",
        "            self.gpu_memory.append(metrics_dict['gpu_memory_gb'])\n",
        "\n",
        "    def log_validation(self, step, val_loss):\n",
        "        \"\"\"Log validation metrics\"\"\"\n",
        "        if not self.use_validation:\n",
        "            return False\n",
        "\n",
        "        self.val_steps.append(step)\n",
        "        self.val_losses.append(val_loss)\n",
        "\n",
        "        if val_loss < self.best_val_loss:\n",
        "            self.best_val_loss = val_loss\n",
        "            self.best_step = step\n",
        "            self.patience_counter = 0\n",
        "            return True\n",
        "        else:\n",
        "            self.patience_counter += 1\n",
        "            return False\n",
        "\n",
        "    def should_stop_early(self, patience):\n",
        "        \"\"\"Check if early stopping criteria met\"\"\"\n",
        "        if not self.use_validation:\n",
        "            return False\n",
        "        return self.patience_counter >= patience\n",
        "\n",
        "    def plot_training_curves(self, exp_name):\n",
        "        \"\"\"Generate comprehensive training visualization\"\"\"\n",
        "        try:\n",
        "            fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
        "            title_suffix = \" (No Validation)\" if not self.use_validation or not self.val_losses else \"\"\n",
        "            fig.suptitle(f'Training Monitoring Dashboard - {exp_name}{title_suffix}',\n",
        "                        fontsize=16, fontweight='bold')\n",
        "\n",
        "            # 1. Training Loss\n",
        "            ax1 = axes[0, 0]\n",
        "            if self.train_losses:\n",
        "                min_len = min(len(self.steps), len(self.train_losses))\n",
        "                ax1.plot(self.steps[:min_len], self.train_losses[:min_len],\n",
        "                        label='Train Loss', color='blue', alpha=0.7)\n",
        "            if self.use_validation and self.val_losses:\n",
        "                ax1.plot(self.val_steps, self.val_losses, label='Val Loss', color='red',\n",
        "                        marker='o', markersize=4, linestyle='--')\n",
        "                ax1.axvline(x=self.best_step, color='green', linestyle=':',\n",
        "                          label=f'Best Val (step {self.best_step})')\n",
        "            ax1.set_xlabel('Steps')\n",
        "            ax1.set_ylabel('Loss')\n",
        "            ax1.set_title('Training Loss' + (' & Validation' if self.use_validation and self.val_losses else ''))\n",
        "            ax1.legend()\n",
        "            ax1.grid(True, alpha=0.3)\n",
        "\n",
        "            # 2. Learning Rate Schedule\n",
        "            ax2 = axes[0, 1]\n",
        "            if self.learning_rates:\n",
        "                min_len = min(len(self.steps), len(self.learning_rates))\n",
        "                ax2.plot(self.steps[:min_len], self.learning_rates[:min_len],\n",
        "                        color='orange', linewidth=2)\n",
        "                ax2.set_xlabel('Steps')\n",
        "                ax2.set_ylabel('Learning Rate')\n",
        "                ax2.set_title('Learning Rate Schedule')\n",
        "                ax2.grid(True, alpha=0.3)\n",
        "                ax2.set_yscale('log')\n",
        "\n",
        "            # 3. GPU Memory Usage\n",
        "            ax3 = axes[1, 0]\n",
        "            if self.gpu_memory:\n",
        "                ax3.plot(self.steps, self.gpu_memory, color='purple', linewidth=2)\n",
        "                ax3.fill_between(self.steps, self.gpu_memory, alpha=0.3, color='purple')\n",
        "                ax3.set_xlabel('Steps')\n",
        "                ax3.set_ylabel('GPU Memory (GB)')\n",
        "                ax3.set_title('GPU Memory Usage')\n",
        "                ax3.grid(True, alpha=0.3)\n",
        "\n",
        "            # 4. Loss Trend\n",
        "            ax4 = axes[1, 1]\n",
        "            if self.use_validation and self.val_losses and len(self.val_losses) > 1:\n",
        "                train_loss_at_val = []\n",
        "                for val_step in self.val_steps:\n",
        "                    closest_idx = min(range(len(self.steps)),\n",
        "                                    key=lambda i: abs(self.steps[i] - val_step))\n",
        "                    train_loss_at_val.append(self.train_losses[closest_idx])\n",
        "\n",
        "                x = np.arange(len(self.val_losses))\n",
        "                width = 0.35\n",
        "                ax4.bar(x - width/2, train_loss_at_val, width, label='Train Loss',\n",
        "                       color='blue', alpha=0.7)\n",
        "                ax4.bar(x + width/2, self.val_losses, width, label='Val Loss',\n",
        "                       color='red', alpha=0.7)\n",
        "                ax4.set_xlabel('Evaluation Checkpoint')\n",
        "                ax4.set_ylabel('Loss')\n",
        "                ax4.set_title('Train vs Val Loss at Checkpoints')\n",
        "                ax4.legend()\n",
        "                ax4.grid(True, alpha=0.3, axis='y')\n",
        "            else:\n",
        "                if self.train_losses and len(self.train_losses) > 5:\n",
        "                    window_size = max(5, len(self.train_losses) // 20)\n",
        "                    smoothed_losses = []\n",
        "                    for i in range(len(self.train_losses)):\n",
        "                        start = max(0, i - window_size // 2)\n",
        "                        end = min(len(self.train_losses), i + window_size // 2 + 1)\n",
        "                        smoothed_losses.append(np.mean(self.train_losses[start:end]))\n",
        "\n",
        "                    ax4.plot(self.steps, self.train_losses, alpha=0.3, color='blue', label='Raw Loss')\n",
        "                    ax4.plot(self.steps, smoothed_losses, color='darkblue', linewidth=2, label='Smoothed Loss')\n",
        "                    ax4.set_xlabel('Steps')\n",
        "                    ax4.set_ylabel('Loss')\n",
        "                    ax4.set_title('Training Loss Trend (Smoothed)')\n",
        "                    ax4.legend()\n",
        "                    ax4.grid(True, alpha=0.3)\n",
        "\n",
        "            plt.tight_layout()\n",
        "\n",
        "            plot_path = self.output_dir / f\"{exp_name}_training_curves.png\"\n",
        "            plt.savefig(plot_path, dpi=300, bbox_inches='tight')\n",
        "            print(f\" Training curves saved to: {plot_path}\")\n",
        "            plt.close()\n",
        "\n",
        "            return plot_path\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"âš  Warning: Could not generate plots - {e}\")\n",
        "            return None\n",
        "\n",
        "    def generate_summary_report(self, exp_name, training_result):\n",
        "        \"\"\"Generate detailed training summary\"\"\"\n",
        "        try:\n",
        "            report = {\n",
        "                \"experiment_name\": exp_name,\n",
        "                \"training_summary\": training_result,\n",
        "                \"validation_used\": self.use_validation,\n",
        "                \"monitoring_metrics\": {\n",
        "                    \"total_steps\": len(self.steps),\n",
        "                    \"final_train_loss\": self.train_losses[-1] if self.train_losses else None,\n",
        "                    \"best_val_loss\": self.best_val_loss if self.use_validation and self.val_losses else None,\n",
        "                    \"best_step\": self.best_step if self.use_validation and self.val_losses else None,\n",
        "                    \"final_learning_rate\": self.learning_rates[-1] if self.learning_rates else None,\n",
        "                    \"max_gpu_memory_gb\": max(self.gpu_memory) if self.gpu_memory else None,\n",
        "                    \"avg_gpu_memory_gb\": np.mean(self.gpu_memory) if self.gpu_memory else None,\n",
        "                },\n",
        "                \"loss_progression\": {\n",
        "                    \"train_losses\": self.train_losses,\n",
        "                    \"val_losses\": self.val_losses if self.use_validation else [],\n",
        "                    \"train_steps\": self.steps,\n",
        "                    \"val_steps\": self.val_steps if self.use_validation else [],\n",
        "                },\n",
        "                \"timestamp\": datetime.now().isoformat()\n",
        "            }\n",
        "\n",
        "            report_path = self.output_dir / f\"{exp_name}_training_report.json\"\n",
        "            with open(report_path, 'w') as f:\n",
        "                json.dump(report, f, indent=2)\n",
        "            print(f\" Training report saved to: {report_path}\")\n",
        "\n",
        "            return report\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"âš  Warning: Could not generate report - {e}\")\n",
        "            return None\n",
        "\n",
        "    def print_progress(self, step, metrics):\n",
        "        \"\"\"Print training progress\"\"\"\n",
        "        try:\n",
        "            progress_str = f\"Step {step}\"\n",
        "            if 'train_loss' in metrics:\n",
        "                progress_str += f\" | Train Loss: {metrics['train_loss']:.4f}\"\n",
        "            if 'learning_rate' in metrics:\n",
        "                progress_str += f\" | LR: {metrics['learning_rate']:.2e}\"\n",
        "            if 'gpu_memory_gb' in metrics:\n",
        "                progress_str += f\" | GPU: {metrics['gpu_memory_gb']:.2f}GB\"\n",
        "            print(progress_str)\n",
        "        except Exception as e:\n",
        "            print(f\"âš  Warning: Could not print progress - {e}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "U1UjSUfEYkLs",
      "metadata": {
        "id": "U1UjSUfEYkLs"
      },
      "source": [
        "#### Callback for training monitoring"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Y5Bhn3ULp2Lv",
      "metadata": {
        "id": "Y5Bhn3ULp2Lv"
      },
      "outputs": [],
      "source": [
        "class MonitoringCallback(TrainerCallback):\n",
        "    \"\"\"Custom callback for training monitoring\"\"\"\n",
        "\n",
        "    def __init__(self, monitor, use_validation=True, eval_steps=10, patience=5, overfitting_threshold=0.15):\n",
        "        self.monitor = monitor\n",
        "        self.use_validation = use_validation\n",
        "        self.eval_steps = eval_steps\n",
        "        self.patience = patience\n",
        "        self.overfitting_threshold = overfitting_threshold\n",
        "        self.last_train_loss = None\n",
        "\n",
        "    def on_log(self, args, state, control, logs=None, **kwargs):\n",
        "        \"\"\"Called when logging occurs\"\"\"\n",
        "        try:\n",
        "            if logs:\n",
        "                step = state.global_step\n",
        "                metrics = {}\n",
        "\n",
        "                if 'loss' in logs:\n",
        "                    metrics['train_loss'] = logs['loss']\n",
        "                    self.last_train_loss = logs['loss']\n",
        "                if 'learning_rate' in logs:\n",
        "                    metrics['learning_rate'] = logs['learning_rate']\n",
        "                if torch.cuda.is_available():\n",
        "                    metrics['gpu_memory_gb'] = torch.cuda.max_memory_allocated() / 1024**3\n",
        "\n",
        "                self.monitor.log_metrics(step, metrics)\n",
        "                self.monitor.print_progress(step, metrics)\n",
        "        except Exception as e:\n",
        "            print(f\"âš  Monitoring warning in on_log: {e}\")\n",
        "\n",
        "    def on_evaluate(self, args, state, control, metrics=None, **kwargs):\n",
        "        \"\"\"Called after evaluation\"\"\"\n",
        "        try:\n",
        "              if not self.use_validation:\n",
        "                  return control\n",
        "\n",
        "              if metrics and 'eval_loss' in metrics:\n",
        "                  step = state.global_step\n",
        "                  val_loss = metrics['eval_loss']\n",
        "                  improved = self.monitor.log_validation(step, val_loss)\n",
        "\n",
        "                  if self.last_train_loss is not None:\n",
        "                      loss_gap = val_loss - self.last_train_loss\n",
        "\n",
        "                      print(f\"\\n{'='*60}\")\n",
        "                      print(f\"Validation at step {step}: Loss = {val_loss:.4f}\")\n",
        "                      print(f\"Training Loss: {self.last_train_loss:.4f}\")\n",
        "                      print(f\"Gap (Val - Train): {loss_gap:.4f}\")\n",
        "\n",
        "                      if improved:\n",
        "                          print(\" New best model!\")\n",
        "                      else:\n",
        "                          print(f\" No improvement (patience: {self.monitor.patience_counter}/{self.patience})\")\n",
        "\n",
        "                      # Check for overfitting\n",
        "                      if loss_gap > self.overfitting_threshold:\n",
        "                          print(f\"\\n  OVERFITTING DETECTED!\")\n",
        "                          print(f\"   Loss gap ({loss_gap:.4f}) exceeds threshold ({self.overfitting_threshold})\")\n",
        "                          print(f\"   Training will stop to prevent overfitting.\")\n",
        "                          print(f\"   Best checkpoint: step {self.monitor.best_step}\")\n",
        "                          control.should_training_stop = True\n",
        "                          return control\n",
        "\n",
        "                      print(f\"{'='*60}\\n\")\n",
        "\n",
        "                  # Regular early stopping\n",
        "                  if self.monitor.should_stop_early(self.patience):\n",
        "                      print(f\"\\n  Early stopping triggered after {self.patience} evaluations without improvement\")\n",
        "                      control.should_training_stop = True\n",
        "        except Exception as e:\n",
        "              print(f\"âš  Monitoring warning in on_evaluate: {e}\")\n",
        "        return control"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "60d866aa",
      "metadata": {
        "id": "60d866aa"
      },
      "source": [
        "#### Utilities"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f969610c",
      "metadata": {
        "id": "f969610c"
      },
      "outputs": [],
      "source": [
        "def aggressive_cleanup():\n",
        "    \"\"\"Aggressive memory cleanup\"\"\"\n",
        "    gc.collect()\n",
        "    torch.cuda.empty_cache()\n",
        "    torch.cuda.synchronize()\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.reset_peak_memory_stats()\n",
        "\n",
        "def get_experiment_combinations():\n",
        "    \"\"\"Minimal ablation grid\"\"\"\n",
        "    return [\n",
        "        {\n",
        "            \"finetune_vision_layers\": True,\n",
        "            \"finetune_language_layers\": True,\n",
        "            \"finetune_attention_modules\": True,\n",
        "            \"finetune_mlp_modules\": True,\n",
        "        }\n",
        "    ]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "40e6dab2",
      "metadata": {
        "id": "40e6dab2"
      },
      "source": [
        "#### Authentication"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e5879baa",
      "metadata": {
        "id": "e5879baa"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "    user = whoami(args[\"token\"])\n",
        "    print(f\"âœ“ Authenticated as: {user['name']}\")\n",
        "except Exception as e:\n",
        "    print(f\"âš  Authentication warning: {e}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "31382917",
      "metadata": {
        "id": "31382917"
      },
      "source": [
        "#### Dataset preparation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c4b8f1cc",
      "metadata": {
        "id": "c4b8f1cc"
      },
      "outputs": [],
      "source": [
        "INSTRUCTION = (\n",
        "    \"You are an expert radiologist. Analyze the provided medical images accurately.\"\n",
        "    \"State every finding and impression that is visually evident.\"\n",
        "    \"Make it as detailed as possible.\"\n",
        ")\n",
        "\n",
        "def convert_to_conversation(sample):\n",
        "    \"\"\"Convert dataset format to conversation format\"\"\"\n",
        "    content = []\n",
        "    for img in sample[\"images\"]:\n",
        "        content.append({\"type\": \"image\", \"image\": img})\n",
        "    content.append({\"type\": \"text\", \"text\": INSTRUCTION})\n",
        "\n",
        "    conversation = [\n",
        "        {\"role\": \"user\", \"content\": content},\n",
        "        {\"role\": \"assistant\", \"content\": [{\"type\": \"text\", \"text\": sample[\"answer\"]}]}\n",
        "    ]\n",
        "    return {\"messages\": conversation}\n",
        "\n",
        "def load_datasets(dataset_name):\n",
        "    \"\"\"Load train and validation datasets\"\"\"\n",
        "    print(\"Loading datasets...\")\n",
        "    train_ds = load_dataset(dataset_name, split=\"train\")\n",
        "\n",
        "    try:\n",
        "        val_ds = load_dataset(dataset_name, split=\"val\")\n",
        "        print(f\"âœ“ Loaded: {len(train_ds)} train, {len(val_ds)} val samples\")\n",
        "    except Exception as e:\n",
        "        val_ds = None\n",
        "        print(f\"âœ“ Loaded: {len(train_ds)} train samples (no validation)\")\n",
        "\n",
        "    return train_ds, val_ds"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5a539294",
      "metadata": {
        "id": "5a539294"
      },
      "source": [
        "#### Load datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7923c9c9",
      "metadata": {
        "id": "7923c9c9"
      },
      "outputs": [],
      "source": [
        "train_ds, val_ds = load_datasets(args[\"dataset_name\"])\n",
        "train_data = [convert_to_conversation(sample) for sample in train_ds]\n",
        "val_data = [convert_to_conversation(sample) for sample in val_ds] if val_ds else None"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3e8f1111",
      "metadata": {
        "id": "3e8f1111"
      },
      "source": [
        "#### Core training class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e6d7a84c",
      "metadata": {
        "id": "e6d7a84c"
      },
      "outputs": [],
      "source": [
        "class ModelTrainer:\n",
        "    \"\"\"Core training class - no monitoring dependencies\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.results = []\n",
        "        self.trained_models = {}  # Store trained models\n",
        "\n",
        "    def _make_name(self, combo):\n",
        "        return (f\"V{combo['finetune_vision_layers']}_\"\n",
        "                f\"L{combo['finetune_language_layers']}_\"\n",
        "                f\"A{combo['finetune_attention_modules']}_\"\n",
        "                f\"M{combo['finetune_mlp_modules']}\")\n",
        "\n",
        "    def train_model(self, model, tokenizer, combo, train_dataset, args, val_dataset=None):\n",
        "        \"\"\"\n",
        "        Core training function - SAFE from monitoring failures\n",
        "        Returns trained model and tokenizer no matter what\n",
        "        \"\"\"\n",
        "        aggressive_cleanup()\n",
        "        exp_name = self._make_name(combo)\n",
        "        use_validation = val_dataset is not None\n",
        "\n",
        "        print(f\"\\n{'='*30}\")\n",
        "        print(f\"   Starting Training: {exp_name}\")\n",
        "        print(f\"   Validation: {'Enabled' if use_validation else 'Disabled'}\")\n",
        "        print(f\"{'='*30}\")\n",
        "\n",
        "        # Configure LoRA\n",
        "        model = FastVisionModel.get_peft_model(\n",
        "            model,\n",
        "            finetune_vision_layers=combo[\"finetune_vision_layers\"],\n",
        "            finetune_language_layers=combo[\"finetune_language_layers\"],\n",
        "            finetune_attention_modules=combo[\"finetune_attention_modules\"],\n",
        "            finetune_mlp_modules=combo[\"finetune_mlp_modules\"],\n",
        "            r=args[\"lora_r\"],\n",
        "            lora_alpha=args[\"lora_a\"],\n",
        "            lora_dropout=0,\n",
        "            bias=\"none\",\n",
        "            random_state=3407,\n",
        "            use_rslora=False,\n",
        "            loftq_config=None,\n",
        "        )\n",
        "\n",
        "        # Calculate parameters\n",
        "        total = sum(p.numel() for p in model.parameters())\n",
        "        trainable = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "        print(f\"Parameters - Total: {total:,} | Trainable: {trainable:,} ({100*trainable/total:.2f}%)\")\n",
        "\n",
        "        # Prepare for training\n",
        "        mem_before = torch.cuda.max_memory_reserved() / 1024**3\n",
        "        FastVisionModel.for_training(model)\n",
        "\n",
        "        # Training configuration\n",
        "        trainer_args = SFTConfig(\n",
        "            per_device_train_batch_size=args[\"batch_size\"],\n",
        "            per_device_eval_batch_size=args[\"batch_size\"] if use_validation else None,\n",
        "            gradient_accumulation_steps=args[\"gradient_accum\"],\n",
        "            warmup_steps=args[\"warmup\"],\n",
        "            num_train_epochs=args.get(\"num_train_epochs\", 3),\n",
        "            learning_rate=args[\"lr\"],\n",
        "            logging_steps=args[\"logging_steps\"],\n",
        "            eval_strategy=\"steps\" if use_validation else \"no\",\n",
        "            eval_steps=args[\"eval_steps\"] if use_validation else None,\n",
        "            eval_accumulation_steps=args[\"gradient_accum\"],\n",
        "            save_strategy=\"steps\",\n",
        "            save_steps=args[\"save_steps\"],\n",
        "            save_total_limit=args[\"save_total_limit\"],\n",
        "            load_best_model_at_end=use_validation,\n",
        "            metric_for_best_model=\"eval_loss\" if use_validation else None,\n",
        "            optim=\"adamw_8bit\",\n",
        "            weight_decay=0.01,\n",
        "            lr_scheduler_type=\"linear\",\n",
        "            seed=3407,\n",
        "            output_dir=f\"outputs/{exp_name}\",\n",
        "            report_to=\"none\",\n",
        "            dataloader_pin_memory=False,\n",
        "            dataloader_num_workers=0,\n",
        "            # Fine-tuning vision\n",
        "            remove_unused_columns=False,\n",
        "            dataset_text_field=\"\",\n",
        "            dataset_kwargs={\"skip_prepare_dataset\": True},\n",
        "            max_length=args[\"max_length\"],\n",
        "        )\n",
        "\n",
        "        # Create trainer with monitoring\n",
        "        callbacks = []\n",
        "        monitor = None  # Initialize to None\n",
        "        try:\n",
        "            monitor = TrainingMonitor(\n",
        "                output_dir=f\"monitoring/{exp_name}\",  # Separate dir per experiment\n",
        "                use_validation=use_validation\n",
        "            )\n",
        "            callbacks.append(MonitoringCallback(\n",
        "                monitor=monitor,\n",
        "                use_validation=use_validation,\n",
        "                eval_steps=args[\"eval_steps\"],\n",
        "                patience=args[\"early_stopping_patience\"],\n",
        "                overfitting_threshold=args.get(\"overfitting_threshold\", 0.15)\n",
        "            ))\n",
        "            print(\"  Monitoring callback added\")\n",
        "        except Exception as e:\n",
        "            print(f\"  Monitoring callback failed: {e}\")\n",
        "            print(\"   Continuing without monitoring\")\n",
        "            monitor = None  # Ensure it's None if failed\n",
        "\n",
        "        # Create trainer\n",
        "        trainer = SFTTrainer(\n",
        "            model=model,\n",
        "            tokenizer=tokenizer,\n",
        "            data_collator=UnslothVisionDataCollator(model, tokenizer),\n",
        "            train_dataset=train_dataset,\n",
        "            eval_dataset=val_dataset if use_validation else None,\n",
        "            args=trainer_args,\n",
        "            callbacks=callbacks,\n",
        "        )\n",
        "\n",
        "        # Train\n",
        "        print(\"  Training started...\")\n",
        "        try:\n",
        "            # stats = trainer.train()\n",
        "            stats = unsloth_train(trainer)\n",
        "            mem_after = torch.cuda.max_memory_reserved() / 1024**3\n",
        "\n",
        "            result = {\n",
        "                \"experiment_name\": exp_name,\n",
        "                \"configuration\": combo,\n",
        "                \"validation_used\": use_validation,\n",
        "                \"total_parameters\": total,\n",
        "                \"trainable_parameters\": trainable,\n",
        "                \"trainable_percentage\": 100 * trainable / total,\n",
        "                \"training_time\": stats.metrics[\"train_runtime\"],\n",
        "                \"final_train_loss\": stats.metrics[\"train_loss\"],\n",
        "                \"memory_usage_gb\": mem_after - mem_before,\n",
        "                \"timestamp\": datetime.now().isoformat(),\n",
        "                \"status\": \"success\"\n",
        "            }\n",
        "\n",
        "            print(f\"   Training completed successfully!\")\n",
        "            print(f\"   Final loss: {result['final_train_loss']:.4f}\")\n",
        "            print(f\"   Time: {result['training_time']:.2f}s\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Training error: {e}\")\n",
        "            result = {\n",
        "                \"experiment_name\": exp_name,\n",
        "                \"status\": \"failed\",\n",
        "                \"error\": str(e),\n",
        "                \"timestamp\": datetime.now().isoformat()\n",
        "            }\n",
        "\n",
        "        self.results.append(result)\n",
        "        self.trained_models[exp_name] = (model, tokenizer)\n",
        "\n",
        "        if monitor is not None:\n",
        "            try:\n",
        "                monitor.plot_training_curves(exp_name)\n",
        "                monitor.generate_summary_report(exp_name, result)\n",
        "                print(\"Monitoring visualizations saved!\")\n",
        "            except Exception as e:\n",
        "                print(f\"Could not save visualizations: {e}\")\n",
        "                print(\"   But your model is safe!\")\n",
        "\n",
        "        return model, tokenizer, result\n",
        "\n",
        "    def save_checkpoint_as_merged(self, checkpoint_path, output_name, load_in_4bit=True):\n",
        "      try:\n",
        "          print(f\"\\n{'='*60}\")\n",
        "          print(f\"Loading checkpoint: {checkpoint_path}\")\n",
        "\n",
        "          # Load the checkpoint\n",
        "          model, tokenizer = FastVisionModel.from_pretrained(\n",
        "              checkpoint_path,\n",
        "              load_in_4bit=load_in_4bit,\n",
        "          )\n",
        "          print(f\"Checkpoint loaded\")\n",
        "\n",
        "          # Save as merged\n",
        "          print(f\"Saving as merged model: {output_name}\")\n",
        "          model.save_pretrained_merged(\n",
        "              output_name,\n",
        "              tokenizer,\n",
        "              save_method=\"merged_16bit\",\n",
        "          )\n",
        "\n",
        "          # Verify it worked\n",
        "          success, error = self.verify_model_loadable(output_name)\n",
        "          if success:\n",
        "              print(f\"Merged model saved and verified: {output_name}\")\n",
        "              return True\n",
        "          else:\n",
        "              print(f\"Merged model saved but verification failed: {error}\")\n",
        "              return False\n",
        "\n",
        "      except Exception as e:\n",
        "          print(f\"Error: {e}\")\n",
        "          return False\n",
        "\n",
        "    def list_available_checkpoints(self, exp_name=None):\n",
        "      if exp_name:\n",
        "          search_path = f\"outputs/{exp_name}/checkpoint-*\"\n",
        "      else:\n",
        "          search_path = \"outputs/*/checkpoint-*\"\n",
        "\n",
        "      checkpoints = sorted(Path(\".\").glob(search_path))\n",
        "\n",
        "      if checkpoints:\n",
        "          print(f\"\\nFound {len(checkpoints)} checkpoint(s):\")\n",
        "          for cp in checkpoints:\n",
        "              # Extract step number\n",
        "              step = cp.name.split(\"-\")[-1]\n",
        "              print(f\"   Step {step}: {cp}\")\n",
        "      else:\n",
        "          print(\"No checkpoints found\")\n",
        "\n",
        "      return [str(cp) for cp in checkpoints]\n",
        "\n",
        "    def save_model_safe(self, model, tokenizer, save_dir=\"trained_model\"):\n",
        "        \"\"\"Save model safely - will work even if training had issues\"\"\"\n",
        "        try:\n",
        "            print(f\"\\nSaving model to {save_dir}...\")\n",
        "            model.save_pretrained(save_dir)\n",
        "            tokenizer.save_pretrained(save_dir)\n",
        "            print(f\"Model saved successfully to {save_dir}\")\n",
        "            return True\n",
        "        except Exception as e:\n",
        "            print(f\"Error saving model: {e}\")\n",
        "            return False\n",
        "\n",
        "    def save_merged_model(self, model, tokenizer, save_dir=\"trained_model_merged\"):\n",
        "        \"\"\"Save merged model (base + LoRA)\"\"\"\n",
        "        try:\n",
        "            print(f\"\\nSaving merged model to {save_dir}...\")\n",
        "            model.save_pretrained_merged(\n",
        "                save_dir,\n",
        "                tokenizer,\n",
        "                save_method=\"merged_16bit\",\n",
        "            )\n",
        "            print(f\"Merged model saved to {save_dir}\")\n",
        "            return True\n",
        "        except Exception as e:\n",
        "            print(f\"Error saving merged model: {e}\")\n",
        "            return False\n",
        "\n",
        "    def save_results(self, filename=\"training_results.json\"):\n",
        "        \"\"\"Save training results\"\"\"\n",
        "        with open(filename, \"w\") as f:\n",
        "            json.dump(self.results, f, indent=2)\n",
        "        print(f\"   Results saved to {filename}\")\n",
        "\n",
        "    def push_to_hub(self, model_path, repo_name, token=None, private=False):\n",
        "      try:\n",
        "          print(f\"\\n{'='*30}\")\n",
        "          print(f\"Pushing to HuggingFace Hub\")\n",
        "          print(f\"Model: {model_path}\")\n",
        "          print(f\"Repo: {args['hf_username']}/{repo_name}\")\n",
        "          print(f\"{'='*30}\")\n",
        "\n",
        "          # Verify model exists\n",
        "          if not Path(model_path).exists():\n",
        "              print(f\" Model path does not exist: {model_path}\")\n",
        "              return None\n",
        "\n",
        "          # Create full repo ID\n",
        "          repo_id = f\"{args['hf_username']}/{repo_name}\"\n",
        "\n",
        "          # Create repository if it doesn't exist\n",
        "          try:\n",
        "              create_repo(\n",
        "                  repo_id=repo_id,\n",
        "                  token=token,\n",
        "                  private=private,\n",
        "                  exist_ok=True,\n",
        "                  repo_type=\"model\"\n",
        "              )\n",
        "              print(f\" Repository ready: {repo_id}\")\n",
        "          except Exception as e:\n",
        "              print(f\" Repository creation: {e}\")\n",
        "\n",
        "          # Upload model\n",
        "          api = HfApi()\n",
        "          print(f\" Uploading model files...\")\n",
        "\n",
        "          api.upload_folder(\n",
        "              folder_path=model_path,\n",
        "              repo_id=repo_id,\n",
        "              repo_type=\"model\",\n",
        "              token=token,\n",
        "          )\n",
        "\n",
        "          model_url = f\"https://huggingface.co/{repo_id}\"\n",
        "          print(f\" Model uploaded successfully!\")\n",
        "          print(f\" URL: {model_url}\")\n",
        "\n",
        "          return model_url\n",
        "\n",
        "      except Exception as e:\n",
        "          print(f\" Upload failed: {e}\")\n",
        "          return None\n",
        "\n",
        "    def verify_model_loadable(self, save_dir):\n",
        "      try:\n",
        "          from pathlib import Path\n",
        "\n",
        "          # Check directory exists\n",
        "          if not Path(save_dir).exists():\n",
        "              return False, f\"Directory {save_dir} does not exist\"\n",
        "\n",
        "          # Check for required files\n",
        "          required_files = [\"config.json\"]\n",
        "          missing = [f for f in required_files if not (Path(save_dir) / f).exists()]\n",
        "          if missing:\n",
        "              return False, f\"Missing required files: {missing}\"\n",
        "\n",
        "          # Try to actually load the model\n",
        "          print(f\"  Verifying {save_dir} can be loaded...\")\n",
        "          test_model, test_tokenizer = FastVisionModel.from_pretrained(\n",
        "              save_dir,\n",
        "              load_in_4bit=True,\n",
        "          )\n",
        "\n",
        "          # Cleanup\n",
        "          del test_model, test_tokenizer\n",
        "          torch.cuda.empty_cache()\n",
        "\n",
        "          return True, None\n",
        "\n",
        "      except Exception as e:\n",
        "          return False, str(e)\n",
        "\n",
        "    def push_checkpoint_to_hub(self, checkpoint_path, repo_name, token=None, private=False,\n",
        "                           save_as_merged=True):\n",
        "      try:\n",
        "          if save_as_merged:\n",
        "              # Convert checkpoint to merged model first\n",
        "              temp_model_name = f\"temp_merged_for_upload\"\n",
        "              success = self.save_checkpoint_as_merged(\n",
        "                  checkpoint_path=checkpoint_path,\n",
        "                  output_name=temp_model_name\n",
        "              )\n",
        "\n",
        "              if not success:\n",
        "                  print(\" Failed to create merged model\")\n",
        "                  return None\n",
        "\n",
        "              # Upload the merged version\n",
        "              url = self.push_to_hub(temp_model_name, repo_name, token, private)\n",
        "\n",
        "              # Cleanup temp files if needed\n",
        "              # import shutil\n",
        "              # shutil.rmtree(temp_model_name)\n",
        "\n",
        "              return url\n",
        "          else:\n",
        "              # Upload checkpoint directly (LoRA adapter)\n",
        "              return self.push_to_hub(checkpoint_path, repo_name, token, private)\n",
        "\n",
        "      except Exception as e:\n",
        "          print(f\" Error: {e}\")\n",
        "          return None"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b8198a5d",
      "metadata": {
        "id": "b8198a5d"
      },
      "source": [
        "#### Main training execution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f2b75ab5",
      "metadata": {
        "id": "f2b75ab5"
      },
      "outputs": [],
      "source": [
        "print(\"\\n\" + \"=\"*30)\n",
        "print(\"MODEL TRAINING - Core Module\")\n",
        "print(\"=\"*30)\n",
        "\n",
        "# Load base model\n",
        "print(\"\\n Loading base model...\")\n",
        "model, tokenizer = FastVisionModel.from_pretrained(\n",
        "    \"unsloth/Llama-3.2-11B-Vision-Instruct\",\n",
        "    load_in_4bit=True,\n",
        "    use_gradient_checkpointing=\"unsloth\",\n",
        ")\n",
        "print(\" Base model loaded\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "UCsffDLdoKp3",
      "metadata": {
        "id": "UCsffDLdoKp3"
      },
      "outputs": [],
      "source": [
        "# Initialize trainer\n",
        "trainer = ModelTrainer()\n",
        "\n",
        "# Train all configurations\n",
        "\n",
        "for combo in get_experiment_combinations():\n",
        "  combination = combo\n",
        "\n",
        "trained_model, trained_tokenizer, result = trainer.train_model(\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    combo=combination,\n",
        "    train_dataset=train_data,\n",
        "    args=args,\n",
        "    val_dataset=val_data\n",
        ")\n",
        "\n",
        "# Save all results\n",
        "trainer.save_results()\n",
        "\n",
        "print(\"\\n\" + \"=\"*30)\n",
        "print(\" ALL TRAINING COMPLETED!\")\n",
        "print(\"=\"*30)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "mHrQesg_ahth",
      "metadata": {
        "id": "mHrQesg_ahth"
      },
      "source": [
        "#### Save model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "WBMXyEDYW8DP",
      "metadata": {
        "id": "WBMXyEDYW8DP"
      },
      "outputs": [],
      "source": [
        "# Save immediately after training\n",
        "exp_name = trainer._make_name(combo)\n",
        "trainer.save_model_safe(trained_model, trained_tokenizer, f\"model_{exp_name}\")\n",
        "trainer.save_merged_model(trained_model, trained_tokenizer, f\"model_{exp_name}_merged\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eaf2b596",
      "metadata": {
        "id": "eaf2b596"
      },
      "outputs": [],
      "source": [
        "# 1. List all checkpoints\n",
        "# exp_name = \"VTrue_LTrue_ATrue_MTrue\"\n",
        "checkpoints = trainer.list_available_checkpoints(exp_name)\n",
        "\n",
        "# 2. Save a specific checkpoint as merged model\n",
        "trainer.save_checkpoint_as_merged(\n",
        "    checkpoint_path=\"outputs/VTrue_LTrue_ATrue_MTrue/checkpoint-300\",\n",
        "    output_name=\"best_model_before_overfit_step300_merged\"\n",
        ")\n",
        "\n",
        "# # 3. Or save multiple checkpoints to compare\n",
        "# for step in [300, 500, 700]:\n",
        "#     trainer.save_checkpoint_as_merged(\n",
        "#         checkpoint_path=f\"outputs/{exp_name}/checkpoint-{step}\",\n",
        "#         output_name=f\"model_{exp_name}_step{step}_merged\"\n",
        "#     )"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "zshg6tnabRGc",
      "metadata": {
        "id": "zshg6tnabRGc"
      },
      "source": [
        "#### Verify if model saved perfectly"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "lvl83CJ4hZG0",
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "referenced_widgets": [
            "dbbc01e86c58451299f3829f7e578d72"
          ]
        },
        "id": "lvl83CJ4hZG0",
        "outputId": "10b05920-e880-4830-86c4-97f4e693590a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Verifying /content/drive/MyDrive/main/best_model_before_overfit_step300_merged can be loaded...\n",
            "==((====))==  Unsloth 2025.10.1: Fast Mllama patching. Transformers: 4.55.4.\n",
            "   \\\\   /|    NVIDIA L4. Num GPUs = 1. Max memory: 22.161 GB. Platform: Linux.\n",
            "O^O/ \\_/ \\    Torch: 2.8.0+cu126. CUDA: 8.9. CUDA Toolkit: 12.6. Triton: 3.4.0\n",
            "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.32.post2. FA2 = False]\n",
            " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
            "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "dbbc01e86c58451299f3829f7e578d72",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "success, error = trainer.verify_model_loadable(\"/content/drive/MyDrive/main/best_model_before_overfit_step300_merged\")\n",
        "if success:\n",
        "    print(\"Merged model saved and verified\")\n",
        "else:\n",
        "    print(\"Merged model saved but verification failed\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "W8x-rqXia1n5",
      "metadata": {
        "id": "W8x-rqXia1n5"
      },
      "source": [
        "#### Push model to Hugging Face account"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "hRUjF-Vqs0hO",
      "metadata": {
        "id": "hRUjF-Vqs0hO"
      },
      "outputs": [],
      "source": [
        "# Push the final merged model\n",
        "trainer.push_to_hub(\n",
        "    model_path=\"/content/drive/MyDrive/main/best_model_before_overfit_step300_merged\",\n",
        "    repo_name=\"llama-vision-radiology-final\",\n",
        "    token=args[\"token\"],  # Or None to use default\n",
        "    private=False  # Set True if you want private repo\n",
        ")\n",
        "\n",
        "# # Or push the LoRA adapter\n",
        "# trainer.push_to_hub(\n",
        "#     model_path=f\"model_{exp_name}\",\n",
        "#     repo_name=\"llama-vision-radiology-lora\",\n",
        "#     token=args[\"token\"],\n",
        "#     private=False\n",
        "# )"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
